<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Project 3: [Auto]Stitching Photo Mosaics</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 2em; }
    h1, h2, h3 { margin-top: 2em; }
    img { max-width: 300px; height: auto; border: 1px solid #ccc; }
    .med-pic { max-width: 450px; height: auto; border: 1px solid #ccc; }

    .big-pic { max-width: 50vw; }
    .caption { font-size: 0.9em; color: #555; }
    .offsets { font-size: 0.9em; color: #333; margin-bottom: 1em; }
    .section { margin-bottom: 2em; }
    .photorow { display: flex; gap: 1em; align-items: flex-start; flex-wrap: wrap; }
  </style>
</head>
<body>
  <h1>Project 3A: Image Warping and Mosaicing</h1>

  <div class="section">
    <h2>Part A.1: Shoot the Pictures</h2>

    <p>All taken at Berkeley Way West.</p>

    <div class="photorow">
      <div>
        <img src="out/bww41.jpg">
        <div class="caption">bww41</div>
      </div>
      <div>
        <img src="out/bww42.jpg">
        <div class="caption">bww42</div>
      </div>
      <div>
        <img src="out/bww43.jpg">
        <div class="caption">bww43</div>
      </div>
    </div>

    <div class="photorow">
      <div>
        <img src="out/bair51.jpg">
        <div class="caption">bair51</div>
      </div>
      <div>
        <img src="out/bair52.jpg">
        <div class="caption">bair52</div>
      </div>
      <div>
        <img src="out/bair53.jpg">
        <div class="caption">bair53</div>
      </div>
    </div>

    <div class="photorow">
      <div>
        <img src="out/bww31.jpg">
        <div class="caption">bww31</div>
      </div>
      <div>
        <img src="out/bww32.jpg">
        <div class="caption">bww32</div>
      </div>
    </div>
  </div>

  <div class="section">
    <h2>Part A.2: Recover Homographies</h2>

    <p>
      Before warping your images into alignment, you need to recover the homography parameters. 
      The transformation is a homography: p’ = Hp, where H is a 3x3 matrix with 8 degrees of freedom 
      (lower-right corner is a scaling factor, set to 1). One way to recover the homography is via 
      a set of (p’, p) pairs of corresponding points from the two images.
    </p>

    <p>Function implemented:</p>
    <pre><code>H = computeH(im1_pts, im2_pts)</code></pre>
    <p>where <code>im1_pts</code> and <code>im2_pts</code> are n-by-2 matrices holding the (x,y) 
    coordinates of corresponding points.</p>

    <p>
      With n > 4, the system is overdetermined and can be solved via least-squares. Establishing 
      point correspondences is sensitive: small errors can produce large changes in the homography. 
      Typical methods include matplotlib's <code>ginput</code>, online tools, or image editors showing coordinates.
    </p>

    <h3>Correspondences Visualized</h3>
    <div>
      <img src="out/correspondences.png" class="big-pic">
      <div class="caption">Point correspondences used to compute H</div>
    </div>

    <h3>Recovered Homography Matrix</h3>
    <pre><code>
  [[ 4.90792521e-01 -3.03338445e-01  1.61928810e+02]
  [-9.46260426e-02  4.84863462e-01  2.56664447e+02]
  [-1.41222136e-04 -2.10643213e-04  1.00000000e+00]]
    </code></pre>
  </div>

  <div class="section">
    <h2>Part A.3: Warp the Images</h2>

    <p>
      Using the recovered homography, we can warp each image towards a reference image. 
      Two interpolation methods were implemented from scratch using inverse warping:
    </p>
    <ul>
      <li><strong>Nearest Neighbor Interpolation:</strong> Round coordinates to the nearest pixel.</li>
      <li><strong>Bilinear Interpolation:</strong> Weighted average of four neighboring pixels.</li>
    </ul>

    <p>
      These methods were applied for rectification and general warping. Trade-offs: Nearest neighbor is fast but blocky; bilinear is smoother but slower.
    </p>

    <h3>Big Topic Intro Image Pre-Warp</h3>
    <div class="photos">
      <div>
        <img src="out/big_topic_intro_prewarp.png" class="big-pic">
        <div class="caption">Pre-warp image</div>
      </div>
    </div>

    <h3>Big Topic Intro Warps</h3>
    <div class="photorow">
      <div>
        <img src="out/big_topic_intro_nn_warp.jpg" class="med-pic">
        <div class="caption">Nearest Neighbor Warp</div>
      </div>
      <div>
        <img src="out/big_topic_intro_bilinear_warp.jpg" class="med-pic">
        <div class="caption">Bilinear Warp</div>
      </div>
    </div>

    <h3>Foam Room Image Pre-Warp</h3>
    <div class="photos">
      <div>
        <img src="out/foam_room_prewarp.png" class="big-pic">
        <div class="caption">Pre-warp image</div>
      </div>
    </div>

    <h3>Foam Room Warps</h3>
    <div class="photorow">
      <div>
        <img src="out/foam_room_nn_warp.jpg" class="med-pic">
        <div class="caption">Nearest Neighbor Warp</div>
      </div>
      <div>
        <img src="out/foam_room_bilinear_warp.jpg" class="med-pic">
        <div class="caption">Bilinear Warp</div>
      </div>
    </div>

  </div>

  <div class="section">
    <h2>Part A.4: Blend the Images into a Mosaic</h2>

    <p>
      After warping the images using the recovered homographies, we create mosaics to stitch multiple images 
      seamlessly. Instead of simply overlaying images—which can produce strong edge artifacts—we use a 
      blending approach based on weighted averaging.
    </p>

    <p><strong>Procedure:</strong></p>
    <ol>
      <li>
        <strong>Reference frame selection:</strong> Choose one image as the reference coordinate frame. All other images are warped relative to this reference.
      </li>
      <li>
        <strong>Propagate homographies:</strong> For images left of the reference, chain the homographies from each adjacent pair to map them into the reference frame. For images right of the reference, propagate inverses of homographies similarly. This ensures all images are consistently aligned.
      </li>
      <li>
        <strong>Compute canvas bounds:</strong> Transform the corners of all images using their respective homographies to determine the overall size of the mosaic canvas.
      </li>
      <li>
        <strong>Warp images onto the canvas:</strong> Each image is warped into the canvas using bilinear interpolation. This preserves smooth transitions and reduces artifacts.
      </li>
    </ol>

    <p>
      <strong>Blending:</strong> In overlapping regions, we apply feathered alpha blending.
      As images are added, we feather the edges (50 pixels of the border) of the new image to create a smooth transition.
      This weighted averaging is only applied to pixels that overlap with existing content on the canvas.
      This creates smooth transitions between images, minimizing visible seams.
    </p>

    <h3>Mosaic Set 1: bww41, bww42, bww43 (with feathering example)</h3>
    <div class="photorow">
      <img src="out/bww41.jpg">
      <img src="out/bww42.jpg">
      <img src="out/bww43.jpg">
    </div>
    <div class="photorow">
      <img src="out/bww4_step1.jpg">
      <img src="out/bww4_step2.jpg">
      <img src="out/bww4_step3.jpg">
    </div>
    <div class="photorow">
      <div>
        <img src="out/bww4_feather1.jpg" class="med-pic">
        <div class="caption">Feathered alpha masks</div>
      </div>
      <img src="out/bww4_feather2.jpg" class="med-pic">
    </div>

    <br>
    <div>
      <img src="out/bww4_mosaic.jpg" class="big-pic">
    </div>


    <h3>Mosaic Set 2: bair51, bair52, bair53</h3>
    <div class="photorow">
      <img src="out/bair51.jpg">
      <img src="out/bair52.jpg">
      <img src="out/bair53.jpg">
    </div>
    <div>
      <img src="out/bair5_mosaic.jpg" class="big-pic">
    </div>

    <h3>Mosaic Set 3: bww31, bww32</h3>
    <div class="photorow">
      <img src="out/bww31.jpg">
      <img src="out/bww32.jpg">
    </div>
    <div>
      <img src="out/bww3_mosaic.jpg" class="big-pic">
    </div>
  </div>

  <h1>Project 3B: Feature Matching for Autostitching</h1>

  <!-- Part B: Feature Matching for Autostitching -->
  <div class="section">
    <h2>Part B.1: Harris Corner Detection</h2>

    <p>Harris corners detected (single-scale) and ANMS-selected corners shown below.</p>

    <p>
      Note that before suppression, there are many detected corners, as we take the max
      "cornerness" over a 3x3 neighborhood. To make computation of ANMS manageable, we filter out points that have
      below average cornerness. After applying ANMS (Adaptive Non-Maximal Suppression),
      we select a more manageable number of well-distributed corners for descriptor extraction and matching.
    </p>

    <div class="photorow">
      <div>
        <img src="out/bww31_harris.png" class="big-pic">
        <div class="caption">Harris corners overlaid on bww31</div>
      </div>
      <div>
        <img src="out/bww31_anms.png" class="big-pic">
        <div class="caption">ANMS-selected corners on bww31</div>
      </div>
    </div>
  </div>

  <div class="section">
    <h2>Part B.2: Feature Descriptor Extraction</h2>

    <p>Example extracted, bias/gain-normalized 8×8 descriptors (downsampled from 40×40 windows centered on each corner).</p>

    <div class="photorow">
      <div>
        <img src="out/bww31_feature_descriptions.png" class="big-pic">
        <div class="caption">Sample feature descriptors from bww31 (8×8 visualizations)</div>
      </div>
    </div>
  </div>

  <div class="section">
    <h2>Part B.3: Feature Matching</h2>

    <p>
      Matches between image pairs using Lowe's heuristic. I used a threshold of 0.5,
      meaning the distance to the closest descriptor must be less than half the distance to the second-closest
      descriptor to be considered a match.
    </p>

    <div class="photorow">
      <div>
        <img src="out/bww31_bww32_matches.png" class="big-pic">
        <div class="caption">Matched features between bww31 and bww32</div>
      </div>
    </div>
  </div>

  <div class="section">
    <h2>Part B.4: RANSAC for Robust Homography</h2>

    <p>4-point RANSAC used to compute robust homographies. Below: manual stitching vs automatic (RANSAC-based) stitching comparisons and automatic mosaics.</p>

    <h3>Manual vs Automatic Comparison</h3>
    <div class="photorow">
      <div>
        <img src="out/bww3_mosaic.jpg" class="med-pic">
        <div class="caption">Manual mosaic (bww31, bww32)</div>
      </div>
      <div>
        <img src="out/bww3_mosaic_auto.jpg" class="med-pic">
        <div class="caption">Automatic mosaic via feature matching + RANSAC (bww31, bww32)</div>
      </div>
    </div>

    <div class="photorow">
      <div>
        <img src="out/bww4_mosaic.jpg" class="med-pic">
        <div class="caption">Manual mosaic (bww41, bww42, bww43)</div>
      </div>
      <div>
        <img src="out/bww4_mosaic_auto.jpg" class="med-pic">
        <div class="caption">Automatic mosaic via feature matching + RANSAC (bww41, bww42, bww43)</div>
      </div>
    </div>

    <div class="photorow">
      <div>
        <img src="out/bair5_mosaic.jpg" class="med-pic">
        <div class="caption">Manual mosaic (bair51, bair52, bair53)</div>
      </div>
      <div>
        <img src="out/bair5_mosaic_auto.jpg" class="med-pic">
        <div class="caption">Automatic mosaic via feature matching + RANSAC (bair51, bair52, bair53)</div>
      </div>
    </div>

    <p>Three automatic mosaics produced using the pipeline above (feature detection → descriptor extraction → NN-ratio matching → 4-point RANSAC → warp & blend).</p>
  </div>


</body>
</html>